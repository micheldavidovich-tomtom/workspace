{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"a2e769bb-1368-4fe4-a9ff-445de05f00a8","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing ./wheels/maps_analytics_utils-1.1-py3-none-any.whl\n","Collecting Scrapy\n","  Downloading Scrapy-2.7.0-py2.py3-none-any.whl (270 kB)\n","\u001b[K     |████████████████████████████████| 270 kB 2.0 MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: pandas in /home/vscode/.local/lib/python3.8/site-packages (from maps-analytics-utils==1.1) (1.1.5)\n","Collecting autopep8\n","  Downloading autopep8-1.7.0-py2.py3-none-any.whl (45 kB)\n","\u001b[K     |████████████████████████████████| 45 kB 1.8 MB/s eta 0:00:011\n","\u001b[?25hCollecting tqdm\n","  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n","\u001b[K     |████████████████████████████████| 78 kB 926 kB/s eta 0:00:011\n","\u001b[?25hCollecting trimesh\n","  Downloading trimesh-3.15.7-py3-none-any.whl (661 kB)\n","\u001b[K     |████████████████████████████████| 661 kB 5.7 MB/s eta 0:00:01\n","\u001b[?25hCollecting http-request-randomizer==1.3.2\n","  Using cached http_request_randomizer-1.3.2.tar.gz (10.9 MB)\n","Requirement already satisfied: python-dotenv in /home/vscode/.local/lib/python3.8/site-packages (from maps-analytics-utils==1.1) (0.21.0)\n","Requirement already satisfied: flake8 in /home/vscode/.local/lib/python3.8/site-packages (from maps-analytics-utils==1.1) (5.0.4)\n","Requirement already satisfied: folium in /usr/local/lib/python3.8/dist-packages (from maps-analytics-utils==1.1) (0.12.1.post1)\n","Collecting typing\n","  Using cached typing-3.7.4.3.tar.gz (78 kB)\n","Requirement already satisfied: numpy in /home/vscode/.local/lib/python3.8/site-packages (from maps-analytics-utils==1.1) (1.23.3)\n","Requirement already satisfied: pyspark in /usr/local/lib/python3.8/dist-packages (from maps-analytics-utils==1.1) (3.1.2)\n","Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from maps-analytics-utils==1.1) (0.34.2)\n","Collecting paramiko\n","  Downloading paramiko-2.11.0-py2.py3-none-any.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 32.5 MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from maps-analytics-utils==1.1) (2.25.1)\n","Requirement already satisfied: googlemaps in /usr/local/lib/python3.8/dist-packages (from maps-analytics-utils==1.1) (4.5.3)\n","Collecting configparser\n","  Downloading configparser-5.3.0-py3-none-any.whl (19 kB)\n","Collecting google-services-api\n","  Downloading google_services_api-1.5.0-py3-none-any.whl (12 kB)\n","Requirement already satisfied: psycopg2-binary in /usr/local/lib/python3.8/dist-packages (from maps-analytics-utils==1.1) (2.8.5)\n","Collecting selenium\n","  Downloading selenium-4.5.0-py3-none-any.whl (995 kB)\n","\u001b[K     |████████████████████████████████| 995 kB 6.3 MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: azure-kusto-data in /home/vscode/.local/lib/python3.8/site-packages (from maps-analytics-utils==1.1) (3.1.3)\n","Requirement already satisfied: country-converter in /usr/local/lib/python3.8/dist-packages (from maps-analytics-utils==1.1) (0.7.7)\n","Requirement already satisfied: coverage in /home/vscode/.local/lib/python3.8/site-packages (from maps-analytics-utils==1.1) (6.5.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from maps-analytics-utils==1.1) (1.6.2)\n","Requirement already satisfied: jedi in /usr/local/lib/python3.8/dist-packages (from maps-analytics-utils==1.1) (0.17.2)\n","Collecting retry\n","  Downloading retry-0.9.2-py2.py3-none-any.whl (8.0 kB)\n","Requirement already satisfied: setuptools in /home/vscode/.local/lib/python3.8/site-packages (from maps-analytics-utils==1.1) (56.0.0)\n","Requirement already satisfied: Sphinx in /home/vscode/.local/lib/python3.8/site-packages (from maps-analytics-utils==1.1) (5.3.0)\n","Collecting webdriver-manager\n","  Downloading webdriver_manager-3.8.4-py2.py3-none-any.whl (27 kB)\n","Requirement already satisfied: awscli in /home/vscode/.local/lib/python3.8/site-packages (from maps-analytics-utils==1.1) (1.26.1)\n","Collecting queuelib>=1.4.2\n","  Downloading queuelib-1.6.2-py2.py3-none-any.whl (13 kB)\n","Requirement already satisfied: packaging in /home/vscode/.local/lib/python3.8/site-packages (from Scrapy->maps-analytics-utils==1.1) (21.3)\n","Requirement already satisfied: cryptography>=3.3 in /home/vscode/.local/lib/python3.8/site-packages (from Scrapy->maps-analytics-utils==1.1) (38.0.1)\n","Collecting itemloaders>=1.0.1\n","  Downloading itemloaders-1.0.6-py3-none-any.whl (11 kB)\n","Collecting parsel>=1.5.0\n","  Downloading parsel-1.6.0-py2.py3-none-any.whl (13 kB)\n","Collecting Twisted>=18.9.0\n","  Downloading Twisted-22.8.0-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 4.4 MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: zope.interface>=5.1.0 in /usr/local/lib/python3.8/dist-packages (from Scrapy->maps-analytics-utils==1.1) (5.4.0)\n","Collecting itemadapter>=0.1.0\n","  Downloading itemadapter-0.7.0-py3-none-any.whl (10 kB)\n","Collecting lxml>=4.3.0\n","  Downloading lxml-4.9.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.9 MB)\n","\u001b[K     |████████████████████████████████| 6.9 MB 860 kB/s eta 0:00:01\n","\u001b[?25hCollecting cssselect>=0.9.1\n","  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n","Collecting pyOpenSSL>=21.0.0\n","  Downloading pyOpenSSL-22.1.0-py3-none-any.whl (57 kB)\n","\u001b[K     |████████████████████████████████| 57 kB 3.1 MB/s eta 0:00:011\n","\u001b[?25hCollecting tldextract\n","  Downloading tldextract-3.4.0-py3-none-any.whl (93 kB)\n","\u001b[K     |████████████████████████████████| 93 kB 1.2 MB/s eta 0:00:011\n","\u001b[?25hCollecting protego>=0.1.15\n","  Downloading Protego-0.2.1-py2.py3-none-any.whl (8.2 kB)\n","Collecting PyDispatcher>=2.0.5; platform_python_implementation == \"CPython\"\n","  Downloading PyDispatcher-2.0.6.tar.gz (38 kB)\n","Collecting w3lib>=1.17.0\n","  Downloading w3lib-2.0.1-py3-none-any.whl (20 kB)\n","Collecting service-identity>=18.1.0\n","  Downloading service_identity-21.1.0-py2.py3-none-any.whl (12 kB)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.8/dist-packages (from pandas->maps-analytics-utils==1.1) (2020.5)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->maps-analytics-utils==1.1) (2.8.1)\n","Requirement already satisfied: pycodestyle>=2.9.1 in /home/vscode/.local/lib/python3.8/site-packages (from autopep8->maps-analytics-utils==1.1) (2.9.1)\n","Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from autopep8->maps-analytics-utils==1.1) (0.10.2)\n","Requirement already satisfied: beautifulsoup4>=4.9.3 in /usr/local/lib/python3.8/dist-packages (from http-request-randomizer==1.3.2->maps-analytics-utils==1.1) (4.10.0)\n","Collecting httmock>=1.3.0\n","  Downloading httmock-1.4.0-py3-none-any.whl (4.8 kB)\n","Collecting psutil>=5.7.2\n","  Downloading psutil-5.9.3-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (295 kB)\n","\u001b[K     |████████████████████████████████| 295 kB 6.2 MB/s eta 0:00:01\n","\u001b[?25hCollecting fake-useragent>=0.1.11\n","  Downloading fake-useragent-0.1.11.tar.gz (13 kB)\n","Requirement already satisfied: pyflakes<2.6.0,>=2.5.0 in /home/vscode/.local/lib/python3.8/site-packages (from flake8->maps-analytics-utils==1.1) (2.5.0)\n","Requirement already satisfied: mccabe<0.8.0,>=0.7.0 in /home/vscode/.local/lib/python3.8/site-packages (from flake8->maps-analytics-utils==1.1) (0.7.0)\n","Requirement already satisfied: branca>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from folium->maps-analytics-utils==1.1) (0.4.2)\n","Requirement already satisfied: jinja2>=2.9 in /home/vscode/.local/lib/python3.8/site-packages (from folium->maps-analytics-utils==1.1) (3.0.0)\n","Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.8/dist-packages (from pyspark->maps-analytics-utils==1.1) (0.10.9)\n","Collecting bcrypt>=3.1.3\n","  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (593 kB)\n","\u001b[K     |████████████████████████████████| 593 kB 4.5 MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from paramiko->maps-analytics-utils==1.1) (1.15.0)\n","Collecting pynacl>=1.0.1\n","  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n","\u001b[K     |████████████████████████████████| 856 kB 3.9 MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->maps-analytics-utils==1.1) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->maps-analytics-utils==1.1) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->maps-analytics-utils==1.1) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->maps-analytics-utils==1.1) (2020.12.5)\n","Collecting trio-websocket~=0.9\n","  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n","Collecting trio~=0.17\n","  Downloading trio-0.22.0-py3-none-any.whl (384 kB)\n","\u001b[K     |████████████████████████████████| 384 kB 3.8 MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: msal<2,>=1.9.0 in /home/vscode/.local/lib/python3.8/site-packages (from azure-kusto-data->maps-analytics-utils==1.1) (1.20.0)\n","Requirement already satisfied: ijson~=3.1 in /home/vscode/.local/lib/python3.8/site-packages (from azure-kusto-data->maps-analytics-utils==1.1) (3.1.4)\n","Requirement already satisfied: azure-identity<2,>=1.5.0 in /home/vscode/.local/lib/python3.8/site-packages (from azure-kusto-data->maps-analytics-utils==1.1) (1.11.0)\n","Requirement already satisfied: parso<0.8.0,>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from jedi->maps-analytics-utils==1.1) (0.7.0)\n","Collecting py<2.0.0,>=1.4.26\n","  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n","\u001b[K     |████████████████████████████████| 98 kB 3.4 MB/s eta 0:00:011\n","\u001b[?25hRequirement already satisfied: decorator>=3.4.2 in /usr/local/lib/python3.8/dist-packages (from retry->maps-analytics-utils==1.1) (5.0.6)\n","Requirement already satisfied: snowballstemmer>=2.0 in /home/vscode/.local/lib/python3.8/site-packages (from Sphinx->maps-analytics-utils==1.1) (2.2.0)\n","Requirement already satisfied: alabaster<0.8,>=0.7 in /home/vscode/.local/lib/python3.8/site-packages (from Sphinx->maps-analytics-utils==1.1) (0.7.12)\n","Requirement already satisfied: sphinxcontrib-jsmath in /home/vscode/.local/lib/python3.8/site-packages (from Sphinx->maps-analytics-utils==1.1) (1.0.1)\n","Requirement already satisfied: babel>=2.9 in /usr/local/lib/python3.8/dist-packages (from Sphinx->maps-analytics-utils==1.1) (2.9.1)\n","Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /home/vscode/.local/lib/python3.8/site-packages (from Sphinx->maps-analytics-utils==1.1) (1.1.5)\n","Requirement already satisfied: sphinxcontrib-devhelp in /home/vscode/.local/lib/python3.8/site-packages (from Sphinx->maps-analytics-utils==1.1) (1.0.2)\n","Requirement already satisfied: Pygments>=2.12 in /home/vscode/.local/lib/python3.8/site-packages (from Sphinx->maps-analytics-utils==1.1) (2.13.0)\n","Requirement already satisfied: imagesize>=1.3 in /home/vscode/.local/lib/python3.8/site-packages (from Sphinx->maps-analytics-utils==1.1) (1.4.1)\n","Requirement already satisfied: sphinxcontrib-applehelp in /home/vscode/.local/lib/python3.8/site-packages (from Sphinx->maps-analytics-utils==1.1) (1.0.2)\n","Requirement already satisfied: importlib-metadata>=4.8; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from Sphinx->maps-analytics-utils==1.1) (4.12.0)\n","Requirement already satisfied: sphinxcontrib-qthelp in /home/vscode/.local/lib/python3.8/site-packages (from Sphinx->maps-analytics-utils==1.1) (1.0.3)\n","Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /home/vscode/.local/lib/python3.8/site-packages (from Sphinx->maps-analytics-utils==1.1) (2.0.0)\n","Requirement already satisfied: docutils<0.20,>=0.14 in /home/vscode/.local/lib/python3.8/site-packages (from Sphinx->maps-analytics-utils==1.1) (0.16)\n","Requirement already satisfied: botocore==1.28.1 in /home/vscode/.local/lib/python3.8/site-packages (from awscli->maps-analytics-utils==1.1) (1.28.1)\n","Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/vscode/.local/lib/python3.8/site-packages (from awscli->maps-analytics-utils==1.1) (0.6.0)\n","Requirement already satisfied: PyYAML<5.5,>=3.10 in /usr/lib/python3/dist-packages (from awscli->maps-analytics-utils==1.1) (5.3.1)\n","Requirement already satisfied: colorama<0.4.5,>=0.2.5 in /home/vscode/.local/lib/python3.8/site-packages (from awscli->maps-analytics-utils==1.1) (0.4.4)\n","Requirement already satisfied: rsa<4.8,>=3.1.2 in /home/vscode/.local/lib/python3.8/site-packages (from awscli->maps-analytics-utils==1.1) (4.7.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->Scrapy->maps-analytics-utils==1.1) (2.4.7)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.8/dist-packages (from cryptography>=3.3->Scrapy->maps-analytics-utils==1.1) (1.14.5)\n","Requirement already satisfied: jmespath>=0.9.5 in /usr/local/lib/python3.8/dist-packages (from itemloaders>=1.0.1->Scrapy->maps-analytics-utils==1.1) (0.10.0)\n","Collecting hyperlink>=17.1.1\n","  Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n","\u001b[K     |████████████████████████████████| 74 kB 1.9 MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.8/dist-packages (from Twisted>=18.9.0->Scrapy->maps-analytics-utils==1.1) (4.3.0)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.8/dist-packages (from Twisted>=18.9.0->Scrapy->maps-analytics-utils==1.1) (20.3.0)\n","Collecting incremental>=21.3.0\n","  Downloading incremental-22.10.0-py2.py3-none-any.whl (16 kB)\n","Collecting constantly>=15.1\n","  Downloading constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)\n","Collecting Automat>=0.8.0\n","  Downloading Automat-20.2.0-py2.py3-none-any.whl (31 kB)\n","Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.8/dist-packages (from tldextract->Scrapy->maps-analytics-utils==1.1) (3.0.12)\n","Collecting requests-file>=1.4\n","  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n","Requirement already satisfied: pyasn1 in /home/vscode/.local/lib/python3.8/site-packages (from service-identity>=18.1.0->Scrapy->maps-analytics-utils==1.1) (0.4.8)\n","Collecting pyasn1-modules\n","  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n","\u001b[K     |████████████████████████████████| 155 kB 4.1 MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.8/dist-packages (from beautifulsoup4>=4.9.3->http-request-randomizer==1.3.2->maps-analytics-utils==1.1) (2.3.1)\n","Requirement already satisfied: MarkupSafe>=2.0.0rc2 in /home/vscode/.local/lib/python3.8/site-packages (from jinja2>=2.9->folium->maps-analytics-utils==1.1) (2.1.1)\n","Collecting wsproto>=0.14\n","  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: async-generator>=1.10 in /usr/local/lib/python3.8/dist-packages (from trio-websocket~=0.9->selenium->maps-analytics-utils==1.1) (1.10)\n","Collecting outcome\n","  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n","Collecting exceptiongroup>=1.0.0rc9; python_version < \"3.11\"\n","  Downloading exceptiongroup-1.0.0rc9-py3-none-any.whl (12 kB)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.8/dist-packages (from trio~=0.17->selenium->maps-analytics-utils==1.1) (1.2.0)\n","Collecting sortedcontainers\n","  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n","Requirement already satisfied: PyJWT[crypto]<3,>=1.0.0 in /home/vscode/.local/lib/python3.8/site-packages (from msal<2,>=1.9.0->azure-kusto-data->maps-analytics-utils==1.1) (2.6.0)\n","Requirement already satisfied: azure-core<2.0.0,>=1.11.0 in /home/vscode/.local/lib/python3.8/site-packages (from azure-identity<2,>=1.5.0->azure-kusto-data->maps-analytics-utils==1.1) (1.26.0)\n","Requirement already satisfied: msal-extensions<2.0.0,>=0.3.0 in /home/vscode/.local/lib/python3.8/site-packages (from azure-identity<2,>=1.5.0->azure-kusto-data->maps-analytics-utils==1.1) (1.0.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8; python_version < \"3.10\"->Sphinx->maps-analytics-utils==1.1) (3.8.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.12->cryptography>=3.3->Scrapy->maps-analytics-utils==1.1) (2.20)\n","Collecting h11<1,>=0.9.0\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 2.4 MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: portalocker<3,>=1.0; python_version >= \"3.5\" and platform_system != \"Windows\" in /home/vscode/.local/lib/python3.8/site-packages (from msal-extensions<2.0.0,>=0.3.0->azure-identity<2,>=1.5.0->azure-kusto-data->maps-analytics-utils==1.1) (2.6.0)\n","Building wheels for collected packages: http-request-randomizer, typing, PyDispatcher, fake-useragent\n","  Building wheel for http-request-randomizer (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for http-request-randomizer: filename=http_request_randomizer-1.3.2-py3-none-any.whl size=33036 sha256=09b9e37348c950594e90f491359329265ad326989bc524acc699728079413574\n","  Stored in directory: /home/vscode/.cache/pip/wheels/1c/8f/d8/d756a1869c561ed926cd0217c2b275ed61e9659c6bf11bab88\n","  Building wheel for typing (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26308 sha256=0236cea6a61c317c1805dbcbc5932b7bca1eee0c2203849a84bf02d076cefbf9\n","  Stored in directory: /home/vscode/.cache/pip/wheels/5e/5d/01/3083e091b57809dad979ea543def62d9d878950e3e74f0c930\n","  Building wheel for PyDispatcher (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for PyDispatcher: filename=PyDispatcher-2.0.6-py3-none-any.whl size=11960 sha256=d33e689bab670072fe9143367a4296d2f6b7ea98faf7c4aa8681073451310954\n","  Stored in directory: /home/vscode/.cache/pip/wheels/dc/b9/4a/948b1176e084b9e3f85e4ffc3d08f817b1fdf0d973bbb94f81\n","  Building wheel for fake-useragent (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for fake-useragent: filename=fake_useragent-0.1.11-py3-none-any.whl size=13487 sha256=c8743901f0b1e464e9984908dac11e1ec0a0ecf8d95fc41dee436ad6c44f97ff\n","  Stored in directory: /home/vscode/.cache/pip/wheels/a0/b8/b7/8c942b2c5be5158b874a88195116b05ad124bac795f6665e65\n","Successfully built http-request-randomizer typing PyDispatcher fake-useragent\n","\u001b[31mERROR: selenium 4.5.0 has requirement certifi>=2021.10.8, but you'll have certifi 2020.12.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: selenium 4.5.0 has requirement urllib3[socks]~=1.26, but you'll have urllib3 1.25.11 which is incompatible.\u001b[0m\n","Installing collected packages: queuelib, itemadapter, w3lib, cssselect, lxml, parsel, itemloaders, hyperlink, incremental, constantly, Automat, Twisted, pyOpenSSL, requests-file, tldextract, protego, PyDispatcher, pyasn1-modules, service-identity, Scrapy, autopep8, tqdm, trimesh, httmock, psutil, fake-useragent, http-request-randomizer, typing, bcrypt, pynacl, paramiko, configparser, google-services-api, h11, wsproto, outcome, exceptiongroup, sortedcontainers, trio, trio-websocket, selenium, py, retry, webdriver-manager, maps-analytics-utils\n","  Attempting uninstall: maps-analytics-utils\n","    Found existing installation: maps-analytics-utils 0.0.1\n","    Uninstalling maps-analytics-utils-0.0.1:\n","      Successfully uninstalled maps-analytics-utils-0.0.1\n","Successfully installed Automat-20.2.0 PyDispatcher-2.0.6 Scrapy-2.7.0 Twisted-22.8.0 autopep8-1.7.0 bcrypt-4.0.1 configparser-5.3.0 constantly-15.1.0 cssselect-1.1.0 exceptiongroup-1.0.0rc9 fake-useragent-0.1.11 google-services-api-1.5.0 h11-0.14.0 httmock-1.4.0 http-request-randomizer-1.3.2 hyperlink-21.0.0 incremental-22.10.0 itemadapter-0.7.0 itemloaders-1.0.6 lxml-4.9.1 maps-analytics-utils-1.1 outcome-1.2.0 paramiko-2.11.0 parsel-1.6.0 protego-0.2.1 psutil-5.9.3 py-1.11.0 pyOpenSSL-22.1.0 pyasn1-modules-0.2.8 pynacl-1.5.0 queuelib-1.6.2 requests-file-1.5.1 retry-0.9.2 selenium-4.5.0 service-identity-21.1.0 sortedcontainers-2.4.0 tldextract-3.4.0 tqdm-4.64.1 trimesh-3.15.7 trio-0.22.0 trio-websocket-0.9.2 typing-3.7.4.3 w3lib-2.0.1 webdriver-manager-3.8.4 wsproto-1.2.0\n","Requirement already satisfied: pycountry in /usr/local/lib/python3.8/dist-packages (22.3.5)\n","Requirement already satisfied: setuptools in /home/vscode/.local/lib/python3.8/site-packages (from pycountry) (56.0.0)\n","Requirement already satisfied: country_list in /usr/local/lib/python3.8/dist-packages (1.0.0)\n","Requirement already satisfied: country_converter in /usr/local/lib/python3.8/dist-packages (0.7.7)\n","Requirement already satisfied: pandas>=1.0 in /home/vscode/.local/lib/python3.8/site-packages (from country_converter) (1.1.5)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0->country_converter) (2020.5)\n","Requirement already satisfied: numpy>=1.15.4 in /home/vscode/.local/lib/python3.8/site-packages (from pandas>=1.0->country_converter) (1.23.3)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0->country_converter) (2.8.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0->country_converter) (1.15.0)\n","Requirement already satisfied: regex in /home/vscode/.local/lib/python3.8/site-packages (2022.9.13)\n"]}],"source":["#! pip install https://repository.tomtomgroup.com/repository/nexus-maps-analytics-utils/packages/maps-analytics-utils/0.0.1/maps_analytics_utils-0.0.1-py3-none-any.whl\n","! pip install wheels/*\n","! pip install pycountry\n","! pip install country_list\n","! pip install country_converter\n","! pip install regex"]},{"cell_type":"code","execution_count":12,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"6fc4e938-ef39-490e-89f1-b70e4d26c48f","showTitle":false,"title":""}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import pycountry\n","from maps_analytics_utils.connections import adx, connections_utils\n","from country_list import countries_for_language, available_languages\n","import typing\n","import country_converter\n","import json\n","import re\n","import matplotlib.pyplot as plt\n","import regex\n","from datetime import date\n","from pyspark.sql.functions import DataFrame\n","import datetime"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"25ce5f10-c371-4bd9-80ed-8ad885778d6c","showTitle":false,"title":""}},"source":["## Setting up the country to use:"]},{"cell_type":"code","execution_count":26,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"7af7ca68-ce4d-4b1f-aa8a-b97e6b586b50","showTitle":false,"title":""}},"outputs":[],"source":["today = datetime.datetime.today().strftime('%d-%m-%Y')\n","countries = ['PT', 'TR']\n","endpoint_list = None  ## If you are using only 1 endpoint you should use a comma at the end: ('search 2 search', )\n","table = 'search_logs_insights'\n","only_full_addresses = False\n","sample = 500000\n","ago = '365'\n","exclude_endpoint = ('search 2 poiSearch')\n","developer_emails_list = 'maps.analytics.metrics@groups.tomtom.com'\n","deduplicate = True"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"f8b5a064-9f3c-450d-bfdd-3fb0f5595f61","showTitle":false,"title":""}},"source":["## Building the functions for ADX:"]},{"cell_type":"code","execution_count":27,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"a6b8acc8-e77f-4f66-8055-3fb5766d6c36","showTitle":false,"title":""}},"outputs":[],"source":["def generate_countries_spellings(country_codes: typing.List[str] or str = None,\n","                                 languages: typing.List[str] = None) -> pd.DataFrame:\n","    \"\"\"Generates a DataFrame with spellings in different languages for a country\n","    :param country_codes: string or list of strings of ISO-2 codes of a country ('ES', not 'ESP'), defaults to None\n","    :type country_codes: str or list, optional\n","    :param languages: list of languages to get the spellings from, defaults to None\n","    :type languages: list, optional\n","    :return: DataFrame with two columns: country code and spellings\n","    :rtype: pd.DataFrame\n","    \"\"\"\n","    \n","    # Get all country keys\n","    if country_codes is None:\n","        country_codes=list(dict(countries_for_language('en')).keys())\n","    \n","    \n","    # If country code is not a list, convert to list with one element\n","    if type(country_codes) != list:\n","        country_codes = [country_codes]\n","    \n","    \n","    # Define languages to query\n","    if languages is None:\n","        languages = [lang for lang in available_languages() if len(lang)==2]\n","    \n","    \n","    # Find country spellings \n","    country_spellings = [(country, [dict(countries_for_language(lang))[country.upper()] for lang in languages]) for country in country_codes]\n","    \n","    \n","    # Drop duplicates\n","    country_spellings = [(country, list(set(spellings))) for country, spellings in country_spellings]\n","    \n","    \n","    # Add ISO codes to list of spellings\n","    country_spellings = [(country, spellings + [country.upper(), pycountry.countries.get(alpha_2=country.upper()).alpha_3]) \n","                        for country, spellings in country_spellings]\n","\n","\n","    # Add official name if exists\n","    country_spellings = [(country, spellings + [pycountry.countries.get(alpha_2=country.upper()).official_name])\n","                         if 'official_name' in str(pycountry.countries.get(alpha_2=country))\n","                         else (country, spellings)\n","                         for country, spellings in country_spellings]\n","    \n","    \n","    return pd.DataFrame(country_spellings, columns=['country_code', 'spellings'])\n","\n","def query_addresses_new(\n","    country_names: typing.List[str] or typing.Tuple[str] or None,\n","    populated_fields: typing.List[str] or typing.Tuple[str] or None,\n","    country: str,\n","    table: str = 'search_logs_insights',\n","    endpoint_list: typing.List[str] or typing.Tuple[str] or None = None,\n","    exclude_endpoint_list: typing.List[str] or typing.Tuple[str] or None = ('search 2 poiSearch'),\n","    developer_emails_list: typing.List[str] or typing.Tuple[str] or None = ('maps.analytics.metrics@groups.tomtom.com', ''),\n","    only_full_addresses: bool = True,\n","    sample: int or None = 100000,\n","    ago: int or None = 365,\n","    check_query: bool = False,\n","    deduplicate: bool = True,\n","    filter_results: int = 10000000\n",") -> str:\n","\n","    \"\"\"Function that generates the string query in KQL (kusto query language) to perform in ADX.\n","\n","    :param country_names: List of names the country can have. Most countries have a lot of denominations and in ADX, the countries denominations are not consistent. So, in order to obtain all possible results, we pass this argument that contain a lot of possible country denominations. This are generated using the \"get_country_spellings\" function.\n","    :type country_names: typing.List[str] or typing.Tuple[str] or None\n","    :param populated_fields: List of populated fields to be selected from the query. Generally, the \"only_full_address\" parameter is good enough to select all complete addresses, but the populated fields lets you select those responses that have some specific fields included in the response. For example, populated field number \"4\" is equivalent to house number!\n","    :type populated_fields: typing.List[str] or typing.Tuple[str] or None\n","    :param country: Country to be casted to the address column. In order to be consistent with the process it must be the country expresses in its three letter ISO code. So if the country is SPAIN, you should pass 'ESP'.\n","    :type country: str\n","    :param table: Table on which you want to perform the query, defaults to 'search_logs_insights'\n","    :type table: str, optional\n","    :param endpoint_list: List of the endpoints you want to filter out for your query, defaults to None, which means no endpoint will be filtered out. \n","    :type endpoint_list: typing.List[str] or typing.Tuple[str] or None, optional\n","    :param exclude_endpoint_list: List of endpoints to exclude from the query, in case you don't want them to appear. Defaults to \"search 2 poiSearch\" since the poi endpoint doesn't provide relevant information for the india process.\n","    :type exclude_endpoint_list: typing.List[str] or typing.Tuple[str] or str or None\n","    :param developer_emails_list: List that determines which emails the query should remove from TT developers (like maps analytics). You can pass elements within a list and they will be removed from the search, defaults to ('maps.analytics.metrics@groups.tomtom.com', ''), which means only the maps analytics emails will be exluded.\n","    :type developer_emails_list: typing.List[str] or typing.Tuple[str] or None, optional\n","    :param only_full_addresses: Boolean that defines if we are looking only for complete addresses or not. This should be set to True if we only want to get complete results (addresses that haave information up to APT level), defaults to True\n","    :type only_full_addresses: bool, optional\n","    :param sample: Sample size you want to extract, defaults to 100000\n","    :type sample: int, optional\n","    :param ago: Time (in days) you want the query to include, defaults to 365, which means all queries within 365 days back will be included in the response.\n","    :type ago: int or None, optional\n","    :param check_query: Boolean that allows to print the query that was passed to kusto in order to debug. Only switch to True if you are having problems with the query response or the number of responses. Defaults to False, which means that the query shouldn't be printed.\n","    :type check_query: bool, optional.\n","    :param deduplicate: Boolean that defines if the addresses returns should be deduplicated or not, defaults to True, which means the addresses will be deduplicated.\n","    :type deduplicate: bool, optional\n","    :return: The string to pass to the ADX instance in order to get the response for a specific country.\n","    :rtype: str\n","    \"\"\"\n","\n","    ###### ERROR Handling ######\n","\n","    if not ((isinstance(country_names, list)) or (isinstance(country_names, tuple)) or (country_names is not None)):\n","        input = \"country_names\"\n","        raise TypeError('The input \"country_names\" must be a list, tuple or None')\n","    else:\n","        if isinstance(country_names, list):\n","            country_names = tuple(country_names)\n","\n","    if not ((isinstance(populated_fields, list)) or (isinstance(populated_fields, tuple)) or (populated_fields is None)):\n","        input = 'populated_fields'\n","        raise TypeError(f'The input \"{input}\" must be a list, tuple or None')\n","    else:\n","        if isinstance(populated_fields, list):\n","            populated_fields = tuple(populated_fields)\n","\n","    if not ((isinstance(endpoint_list, list)) or (isinstance(endpoint_list, tuple)) or (endpoint_list is None)):\n","        input = 'endpoint_list'\n","        raise TypeError(f'The input \"{input}\" must be a list, tuple or None')\n","    else:\n","        if isinstance(endpoint_list, list):\n","            endpoint_list = tuple(endpoint_list)\n","    \n","    if not (\n","        (isinstance(developer_emails_list, list)) or (isinstance(developer_emails_list, tuple)) or (developer_emails_list is None)\n","        or (isinstance(developer_emails_list, str))\n","    ):\n","        input = 'developer_emails_list'\n","        raise TypeError(f'The input \"{input}\" must be a list, tuple, string or None')\n","    else:\n","        if isinstance(developer_emails_list, list):\n","            developer_emails_list = tuple(developer_emails_list)\n","            \n","    if not (\n","        (isinstance(exclude_endpoint_list, list)) or (isinstance(exclude_endpoint_list, tuple)) or (exclude_endpoint_list is None)\n","        or (isinstance(exclude_endpoint_list, str))\n","    ):\n","        input = 'exclude_endpoint_list'\n","        raise TypeError(f'The input \"{input}\" must be a list, tuple, string or None')\n","    else:\n","        if isinstance(developer_emails_list, list):\n","            developer_emails_list = tuple(developer_emails_list)\n","            \n","    if not ((isinstance(sample, int)) or (sample is None)):\n","        input = 'sample'\n","        raise TypeError(f'The input \"{input}\" must be an int or None')\n","\n","    ############################\n","    \n","    # Turn country_names and populated fields into strings\n","    country_names = str(tuple(country_names))\n","    \n","    ## TODO: Convertir todo lo de abajo en una función externa!! ##\n","    if ago is not None:\n","        look_back = f'| where client_received_start_timestamp > ago({int(ago)}d)'\n","    else:\n","        look_back = ''\n","        \n","    if only_full_addresses:\n","        who_searched = \"| where who_searched == 'Full Address Search'\"\n","    else:\n","        who_searched = ''\n","        \n","    if developer_emails_list is None:\n","        developer_line = ''\n","    elif type(developer_emails_list) == str:\n","        developer_line = f'''| where developer_email !in~ ('{developer_emails_list}')'''\n","    else:\n","        developer_line = f'| where developer_email !in~ {str(developer_emails_list)}'\n","        \n","    if exclude_endpoint_list is None:\n","        developer_line = ''\n","    elif type(exclude_endpoint_list) == str:\n","        exclude_developer_line = f'''| where method_name !in~ ('{exclude_endpoint_list}')'''\n","    else:\n","        exclude_developer_line = f'| where method_name !in~ {str(exclude_endpoint_list)}'\n","\n","    if populated_fields is not None:\n","        populated_fields_string = f\"| where populated_fields in {populated_fields}\"\n","    else:\n","        populated_fields_string = ''\n","\n","    if endpoint_list is not None:\n","        endpoint_string = f'| where method_name in~ {endpoint_list}'\n","    else:\n","        endpoint_string = ''\n","        \n","    if sample is not None:\n","        sample_string = f'| sample {sample}'\n","    else:\n","        sample_string = ''\n","        \n","    order_string = ''\n","        \n","    if deduplicate:\n","        deduplicate_string = '| summarize search_query_counts = count() by request_uri, searched_query, populated_fields, ordered_populated_fields, countryName, who_searched, request_country, method_name, lib_postal_result, parsed_request_quertystring, developer_email, house, near, house_number, road, unit, level, entrance, staircase, po_box, postcode, suburb, city_district, city, island, state_district, state, country_region, world_region'\n","        sample_string = f'| limit {sample}'\n","        order_string = '| order by search_query_counts'\n","    else:\n","        deduplicate_string = ''\n","        \n","    if filter_results is not None:\n","        reduce_sample = f'| limit {filter_results}'\n","    else:\n","        reduce_sample = ''\n","        \n","        \n","    ###############################################################\n","\n","    building_string = f'''{table}\n","                            {look_back}\n","                            {who_searched}\n","                            | where countryName in~ {country_names}\n","                            {endpoint_string}\n","                            {exclude_developer_line}\n","                            {populated_fields_string}\n","                            {developer_line}\n","                            {reduce_sample}\n","                            {deduplicate_string}\n","                            {order_string}\n","                            {sample_string}\n","                            | extend country = '{country}'\n","                        '''\n","    if check_query:\n","        print('THIS IS THE QUERY YOU EXECUTED ON ADX:')\n","        print(building_string)\n","        print('\\n')\n","    \n","    return building_string\n","\n","def parse_populated_fields(df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"Translate the keys from populated fields into readable content\n","    :param df: DataFrame of search logs containing column 'populated_fields' for which the components we wish to translate\n","    :type df: pd.DataFrame\n","    :return: DataFrame with column 'components' which has the 'populated_fields' components in a readable form.\n","    :rtype: pd.DataFrame\n","    \"\"\"\n","    \n","    ## Create connection to ADX and get populated fields master data\n","    #connections_utils_instance = connections_utils.AzureConnections()\n","    tenant_id, client_id, secret_value, secret_id = connections_utils.get_adx_secrets()\n","    adx_instance = adx.AzureDataExplorer()\n","    populated_fields_master_df, _ = adx_instance.execute_adx_query(query='populated_fields_master_data',\n","                                                                   cluster=\"https://ttapianalyticsadxpweu.westeurope.kusto.windows.net\",\n","                                                                   database=\"ttapianalytics-onlineSearch\",\n","                                                                   client_id=client_id,\n","                                                                   secret_id=secret_id,\n","                                                                   tenant_id=tenant_id) \n","    \n","    adx_instance = None\n","    \n","    # Parse\n","    df_copy = df.copy()\n","    \n","    # Create dictionary from 'populated_fields_master_df' to help translate populated fields\n","    fields_dictionary = pd.Series(populated_fields_master_df.populated_field_description.values,\n","                                  index=populated_fields_master_df.populated_field_id.astype(str)).to_dict()\n","\n","\n","    # Split by pipes and substitute each number with their corresponding component\n","    df_copy['components'] = df_copy.populated_fields.str.split('|')\n","\n","    df_copy['components'] = (df_copy\n","                             .components\n","                             .apply(lambda x: [fields_dictionary[comp] for comp in x if comp!=''])\n","                                     )\n","\n","    df_copy['number_components'] = df_copy.components.apply(lambda x: len(x))\n","    \n","    \n","    # Transform back to a single string divided by pipes\n","    df_copy['components'] = df_copy.components.apply(lambda x: '|'.join(x))\n","    \n","    return df_copy\n","\n","def get_country_logs(\n","    country: str, endpoint_list: list or tuple or None = None, table: str = 'search_logs_insights', sample: int=10000, \n","    populated_fields: list or tuple or None = None, developer_emails_list: list or tuple or None = None, ago: int = 365, \n","    exclude_endpoint_list: list or tuple or str or None = ('search 2 poiSearch'), only_full_addresses: bool = True, \n","    check_query: bool = False, deduplicate: bool = True, filter_results: int = 10000000\n",") -> pd.DataFrame:\n","    \"\"\"Gets search logs for a given country\n","    :param country: string of ISO-2 code of a country ('ES', not 'ESP').\n","    :type country: str\n","    :param endpoint_list: List of the endpoints you want to filter out for your query, defaults to None, which means no endpoint will be filtered out. \n","    :type endpoint_list: typing.List[str] or typing.Tuple[str] or None, optional\n","    :param table: wether to query 'search_log_insights_new' instead of 'search_logs_insights', defaults to True\n","    :type table: str, optional\n","    :param sample: Initial sample size, defaults to 10000\n","    :type sample: int, optional\n","    :param populated_fields: List of populated fields to be selected from the query. Generally, the \"only_full_address\" parameter is good enough to select all complete addresses, but the populated fields lets you select those responses that have some specific fields included in the response. For example, populated field number \"4\" is equivalent to house number!\n","    :type populated_fields: typing.List[str] or typing.Tuple[str] or None\n","    :param endpoints: Tuple that contains the endpoints you want to search for. This parameter should only be filled if the value of \"specify_search_method\" is True. Possible values are: search 2 search, search 2 structuredGeocode, search 2 nearbySearch, search 2 geocode, search 2 poiSearch, search 2 categorySearch, etc...\n","    :type endpoints: tuple(str)\n","    :param developer_emails_list: List that determines which emails the query should remove from TT developers (like maps analytics). You can pass elements within a list and they will be removed from the search, defaults to ('maps.analytics.metrics@groups.tomtom.com', ''), which means only the maps analytics emails will be exluded. Defaults to None.\n","    :type developer_emails_list: typing.List[str] or typing.Tuple[str] or None, optional\n","    :param ago: Include how much time (in days) you want to include for the logs that will be returned. Defaults to 365, which means that logs from up to a year back from the date this is run will be included.\n","    :type ago: int or None, optional\n","    :param exclude_endpoint_list: List of endpoints to exclude from the query, in case you don't want them to appear. Defaults to \"search 2 poiSearch\" since the poi endpoint doesn't provide relevant information for the india process.\n","    :type exclude_endpoint_list: typing.List[str] or typing.Tuple[str] or str or None\n","    :param only_full_addresses: Boolean that shows if the search should be done on full addresses only, or if the search should be done on all logs. Defaults to True, which means we are only looking for complete address searches.\n","    :type only_full_addresses: bool, optional\n","    :param check_query: Boolean that allows to print the query that was passed to kusto in order to debug. Only switch to True if you are having problems with the query response or the number of responses. Defaults to False, which means that the query shouldn't be printed.\n","    :type check_query: bool, optional.\n","    :param deduplicate: Boolean that defines if the addresses returns should be deduplicated or not, defaults to True, which means the addresses will be deduplicated.\n","    :type deduplicate: bool, optional\n","    :return: DataFrame with logs for the specified search parameters.\n","    :rtype: pd.DataFrame\n","    \"\"\"\n","\n","    # Country spellings and produce query\n","    country_names = generate_countries_spellings(country)\n","        \n","    query_country = query_addresses_new(\n","        country_names=country_names.spellings[0],\n","        populated_fields=populated_fields,\n","        country=country,\n","        table=table, \n","        endpoint_list=endpoint_list,\n","        developer_emails_list=developer_emails_list,\n","        only_full_addresses=only_full_addresses,\n","        sample=sample,\n","        ago=ago,\n","        check_query=check_query,\n","        deduplicate=deduplicate,\n","        filter_results=filter_results\n","    )\n","\n","    tenant_id, client_id, secret_value, secret_id = connections_utils.get_adx_secrets()\n","    adx_instance = adx.AzureDataExplorer()\n","\n","\n","    addresses_df, _ = adx_instance.execute_adx_query(query=query_country,\n","                                                    cluster=\"https://ttapianalyticsadxpweu.westeurope.kusto.windows.net\",\n","                                                               database=\"ttapianalytics-onlineSearch\",\n","                                                               client_id=client_id,\n","                                                               secret_id=secret_id,\n","                                                               tenant_id=tenant_id) \n","    addresses_df = parse_populated_fields(addresses_df)\n","    addresses_df.countryName = addresses_df.countryName.str.upper()\n","    \n","    \n","    if 'developer_email' not in addresses_df.columns:\n","        addresses_df['developer_email'] = ''\n","    \n","    \n","    # Close connections\n","    adx_instance = None\n","    connections_utils_instance = None\n","\n","    addresses_clients_df = addresses_df.loc[~addresses_df.searched_query.str.contains('�')].reset_index(drop=True)\n","\n","    return addresses_clients_df"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"396b7ac9-1de2-4c74-b0e6-afc7d79c2487","showTitle":false,"title":""}},"source":["### Building a function for sample generation for multiple countries"]},{"cell_type":"code","execution_count":28,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"acd74e6d-7a1e-4f12-9d79-b6c73d2d42ea","showTitle":false,"title":""}},"outputs":[],"source":["def address_components_sample_generator(\n","    country_list: list, endpoint_list: list or tuple or None = None, table: str = 'search_logs_insights', sample: int = 10000, \n","    developer_emails_list: list or tuple or None = None, populated_fields: list or tuple or None = None, only_full_addresses: bool = True, \n","    exclude_endpoint_list: list or tuple or None = ('search 2 poiSearch'), ago: int = 365, check_query: bool = False, \n","    deduplicate: bool = True, filter_results: int = 10000000\n",") -> dict:\n","    '''\n","    Function that receives the list of countries you want to get the sample for in ISO-2 code, a list of endpoints you want to include in your serach, the table you want to use in ADX, etc. It returns a dictionary with the responses for each of the countries in the list.\n","    \n","    :param country_list: List of countries to use in ISO-2 code! For example, if you want the results for Spain and the United States, you should pass country_list = ['ES', 'US'].\n","    :type country_list: list\n","    :param endpoint_list: List of the endpoints you want to filter out for your query, defaults to None, which means no endpoint will be filtered out. \n","    :type endpoint_list: typing.List[str] or typing.Tuple[str] or None, optional\n","    :param table: String that selects which table to get the results from, defaults to 'search_logs_insights' which is the main table where results from queries are stored.\n","    :type table: str, optional\n","    :param sample: Specify the sample size you want for each query, defaults to 10000\n","    :type sample: int, optional\n","    :param developer_emails_list: List that determines which emails the query should remove from TT developers (like maps analytics). You can pass elements within a list and they will be removed from the search, defaults to ('maps.analytics.metrics@groups.tomtom.com', ''), which means only the maps analytics emails will be exluded. Defaults to None.\n","    :type developer_emails_list: typing.List[str] or typing.Tuple[str] or None, optional\n","    :param populated_fields: A list that contains all the populated fields combinations that are valid for a complete address, defaults to None, which means populated_fields are not considered.\n","    :type populated_fields: list or tuple or None, optional\n","    :param only_full_addresses: Determine if the query should require only full addresses (at APT level), defaults to True, which means only complete addresses should be returned in the Kusto query.\n","    :type only_full_addresses: bool, optional\n","    :param exclude_endpoint_list: List of endpoints to exclude from the query, in case you don't want them to appear. Defaults to \"search 2 poiSearch\" since the poi endpoint doesn't provide relevant information for the india process.\n","    :type exclude_endpoint_list: typing.List[str] or typing.Tuple[str] or str or None\n","    :param ago: Time (in number of days) that should be included starting from today's date and going back \"ago\" days, defaults to 365, which means the results will only include queries from up to 365 days back.\n","    :type ago: int, optional\n","    :param check_query: Boolean that allows to print the query that was passed to kusto in order to debug. Only switch to True if you are having problems with the query response or the number of responses. Defaults to False, which means that the query shouldn't be printed.\n","    :type check_query: bool, optional.\n","    :param deduplicate: Boolean that defines if the addresses returns should be deduplicated or not, defaults to True, which means the addresses will be deduplicated.\n","    :type deduplicate: bool, optional\n","    :return: Returns a dictionary with the countries as keys and the query response dataframes as values for each country.\n","    :rtype: dict\n","    '''\n","    # Create an empty dictionary where we will store all the samples by country name:\n","    country_dict = {}\n","    \n","    # Iterate through the country list and call the get_country_logs function on each country:\n","    for country in country_list:\n","        sample_df = get_country_logs(\n","            country=country, endpoint_list=endpoint_list, table=table, sample=sample, populated_fields=populated_fields, \n","            developer_emails_list=developer_emails_list, ago=ago, only_full_addresses=only_full_addresses, \n","            exclude_endpoint_list=exclude_endpoint_list, check_query=check_query, deduplicate=deduplicate, filter_results=filter_results\n","        )\n","        \n","        country_dict[country] = sample_df\n","        \n","    return country_dict"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"cb1fca06-95ef-4910-9e0b-5d6e0cf42970","showTitle":false,"title":""}},"source":["### Building the function to convert country names to the two-letter ISO code"]},{"cell_type":"code","execution_count":29,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"5f7962de-c61a-4de9-8148-43335bed5f90","showTitle":false,"title":""}},"outputs":[],"source":["def get_countries_correctly(countries: list or str):\n","    '''\n","    Function that receives the name of the countries or country and converts it into ISO-2 to be used by the query in ADX.\n","    \n","    :param countries: List of the countries you want to convert to ISO-2\n","    :type countries: list or str\n","    :return: A python list containing the names of the countries converter to ISO-2\n","    :rtype: list\n","    '''\n","    if type(countries) != list:\n","        countries = [countries]\n","    \n","    return [country_converter.convert(country, to='ISO2') for country in countries]"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"9c80949f-6a8e-404e-9f1c-e66f3615a806","showTitle":false,"title":""}},"source":["### Building the function to extract and calculate the parsed components from the tables"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"3a9be5a0-011e-471a-8ec1-4f209adf767a","showTitle":false,"title":""}},"source":["***Below there's a description of Libpostal's address components***\n","\n","- **house:** venue name e.g. \"Brooklyn Academy of Music\", and building names e.g. \"Empire State Building\"\n","- **near:** phrases like \"in\", \"near\", etc. used after a category phrase to help with parsing queries like \"restaurants in Brooklyn\"\n","- **house_number:** usually refers to the external (street-facing) building number. In some countries this may be a compount, hyphenated number which also includes an apartment number, or a block number (a la Japan), but libpostal will just call it the house_number for simplicity.\n","- **road:** street name(s)\n","- **unit:** an apartment, unit, office, lot, or other secondary unit designator\n","- **level:** expressions indicating a floor number e.g. \"3rd Floor\", \"Ground Floor\", etc.\n","- **staircase:** numbered/lettered staircase\n","- **entrance:** numbered/lettered entrance\n","- **po_box:** post office box: typically found in non-physical (mail-only) addresses\n","- **postcode:** postal codes used for mail sorting\n","- **suburb:** usually an unofficial neighborhood name like \"Harlem\", \"South Bronx\", or \"Crown Heights\"\n","- **city_district:** these are usually boroughs or districts within a city that serve some official purpose e.g. \"Brooklyn\" or \"Hackney\" or \"Bratislava IV\"\n","- **city:** any human settlement including cities, towns, villages, hamlets, localities, etc.\n","- **island:** named islands e.g. \"Maui\"\n","- **state_district:** usually a second-level administrative division or county.\n","- **state:** a first-level administrative division. Scotland, Northern Ireland, Wales, and England in the UK are mapped to \"state\" as well (convention used in OSM, GeoPlanet, etc.)\n","- **country_region:** informal subdivision of a country without any political status\n","- **country:** sovereign nations and their dependent territories, anything with an ISO-3166 code.\n","- **world_region:** currently only used for appending “West Indies” after the country name, a pattern frequently used in the English-speaking Caribbean e.g. “Jamaica, West Indies”"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"98dac8f1-80bb-4bdc-83ff-4871f0e57153","showTitle":false,"title":""}},"source":["#### Parsing the libpostal response:"]},{"cell_type":"code","execution_count":30,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"65ea992f-b4f0-4211-88cf-e7e7597a9c7c","showTitle":false,"title":""}},"outputs":[],"source":["def get_libpostal_condition(component, possible_results):\n","    '''\n","    :param possible_results: These are the possible outcomes that this value may have. For example a house number can contain spaces, letters and numbers (think of calle de Goya 23 b --> house number is: \"23 b\")\n","    :type possible_results: str\n","    '''\n","    libpostal_condition = f'\"{component}\":\"{possible_results}\"' + '[,\\}]'\n","    \n","    return libpostal_condition\n","\n","def parse_libpostal(df: pd.DataFrame) -> pd.DataFrame:\n","    ''' Function that parses the Libpostal components and returns a DataFrame with a column for each parsed component in the Libpostal dictionary, mapped to a component in the TomTom documentation, if there is one. If not, we keep the Libpostal component. The DataFrame must contain a column called lib_postal_result, that includes the dictionary in string format of the Libpostal response.\n","    \n","    :param df: DataFrame containing the Libpostal response in a str(dict) format from which you want to extract the components.\n","    :type df: pd.DataFrame\n","    :return: Returns the same DataFrame with the added columns. It will contain 19 extra columns that parse the entire set of component options from the Libpotal response.\n","    :rtype: pd.DataFrame\n","    '''\n","    results = df.copy()\n","    \n","    results['removed_air_quotes'] = results['lib_postal_result'].map(lambda x: re.sub('\"+', '\"', re.sub(\"'+\", \"'\", x)))\n","    \n","    ### house:\n","    house_condition = get_libpostal_condition('house', '(.+?)(?=\")')\n","    results['lp_building_name'] = (   ## Building name is the term used in the TT documentation\n","        results['removed_air_quotes']\n","        .map(lambda x: '' if regex.search(house_condition, x) is None \n","                          else regex.search(house_condition, x).group(1))\n","    )\n","    \n","    ### near:\n","    near_condition = get_libpostal_condition('near', '(.+?)(?=\")')\n","    results['lp_near'] = (\n","        results['removed_air_quotes']\n","        .map(lambda x: '' if regex.search(near_condition, x) is None \n","                          else regex.search(near_condition, x).group(1))\n","    )\n","    \n","    ### house_number:\n","    house_number_condition = get_libpostal_condition('house_number', '(.+?)(?=\")')\n","    results['lp_house_number'] = (\n","        results['removed_air_quotes']\n","        .map(lambda x: '' if regex.search(house_number_condition, x) is None \n","                          else regex.search(house_number_condition, x).group(1))\n","    )\n","    \n","    ### road:\n","    road_condition = get_libpostal_condition('road', '(.+?)(?=\")')\n","    results['lp_road'] = (\n","        results['removed_air_quotes']\n","        .map(lambda x: '' if regex.search(road_condition, x) is None \n","                          else regex.search(road_condition, x).group(1))\n","    )\n","    \n","    ### unit:\n","    unit_condition = get_libpostal_condition('unit', '(.+?)(?=\")')\n","    results['lp_unit'] = (\n","        results['removed_air_quotes']\n","        .map(lambda x: '' if regex.search(unit_condition, x) is None \n","                          else regex.search(unit_condition, x).group(1))\n","    )\n","    \n","    ### level:\n","    level_condition = get_libpostal_condition('level', '(.+?)(?=\")')\n","    results['lp_floor'] = (    ## level is the equivalent of floor in the TT documentation (\"Ground floor, 3rd floor, etc..\")\n","        results['removed_air_quotes']\n","        .map(lambda x: '' if regex.search(level_condition, x) is None \n","                          else regex.search(level_condition, x).group(1))\n","    )\n","    \n","    ### staircase:\n","    staircase_condition = get_libpostal_condition('staircase', '(.+?)(?=\")')\n","    results['lp_staircase'] = (\n","        results['removed_air_quotes']\n","        .map(lambda x: '' if regex.search(staircase_condition, x) is None \n","                          else regex.search(staircase_condition, x).group(1))\n","    )\n","    \n","    ### entrance:\n","    entrance_condition = get_libpostal_condition('entrance', '(.+?)(?=\")')\n","    results['lp_entrance'] = (\n","        results['removed_air_quotes']\n","        .map(lambda x: '' if regex.search(entrance_condition, x) is None \n","                          else regex.search(entrance_condition, x).group(1))\n","    )\n","    \n","    ### postcode:\n","    postal_code_condition = get_libpostal_condition('postcode', '(.+?)(?=\")')\n","    results['lp_postal_code'] = (\n","        results['removed_air_quotes']\n","        .map(lambda x: '' if regex.search(postal_code_condition, x) is None \n","                          else regex.search(postal_code_condition, x).group(1))\n","    )\n","    \n","    ### po_box:\n","    po_box_condition = get_libpostal_condition('po_box', '(.+?)(?=\")')\n","    results['lp_po_box'] = (\n","        results['removed_air_quotes']\n","        .map(lambda x: '' if regex.search(po_box_condition, x) is None \n","                          else regex.search(po_box_condition, x).group(1))\n","    )\n","    \n","    ### suburb:\n","    suburb_condition = get_libpostal_condition('suburb', '(.+?)(?=\")')\n","    results['lp_suburb'] = (\n","        results['removed_air_quotes']\n","        .map(lambda x: '' if regex.search(suburb_condition, x) is None \n","                          else regex.search(suburb_condition, x).group(1))\n","    )\n","    \n","    ### city_district:\n","    city_district_condition = get_libpostal_condition('city_district', '(.+?)(?=\")')\n","    results['lp_city_district'] = (\n","        results['removed_air_quotes']\n","        .map(lambda x: '' if regex.search(city_district_condition, x) is None \n","                          else regex.search(city_district_condition, x).group(1))\n","    )\n","    \n","    ### city:\n","    city_condition = get_libpostal_condition('city', '(.+?)(?=\")')\n","    results['lp_city'] = (\n","        results['removed_air_quotes']\n","        .map(lambda x: '' if regex.search(city_condition, x) is None \n","                          else regex.search(city_condition, x).group(1))\n","    )\n","    \n","    ### island:\n","    island_condition = get_libpostal_condition('island', '(.+?)(?=\")')\n","    results['lp_island'] = (\n","        results['removed_air_quotes']\n","        .map(lambda x: '' if regex.search(island_condition, x) is None \n","                          else regex.search(island_condition, x).group(1))\n","    )\n","    \n","    ### state_district:\n","    state_district_condition = get_libpostal_condition('state_district', '(.+?)(?=\")')\n","    results['lp_state_district'] = (\n","        results['removed_air_quotes']\n","        .map(lambda x: '' if regex.search(state_district_condition, x) is None \n","                          else regex.search(state_district_condition, x).group(1))\n","    )\n","    \n","    ### state:\n","    state_condition = get_libpostal_condition('state', '(.+?)(?=\")')\n","    results['lp_state'] = (\n","        results['removed_air_quotes']\n","        .map(lambda x: '' if regex.search(state_condition, x) is None \n","                          else regex.search(state_condition, x).group(1))\n","    )\n","    \n","    ### country_region\n","    country_region_condition = get_libpostal_condition('country_region', '(.+?)(?=\")')\n","    results['lp_country_region'] = (\n","        results['removed_air_quotes']\n","        .map(lambda x: '' if regex.search(country_region_condition, x) is None \n","                          else regex.search(country_region_condition, x).group(1))\n","    )\n","    \n","    ### country:\n","    country_condition = get_libpostal_condition('country', '(.+?)(?=\")')\n","    results['lp_country'] = (\n","        results['removed_air_quotes']\n","        .map(lambda x: '' if regex.search(country_condition, x) is None \n","                          else regex.search(country_condition, x).group(1))\n","    )\n","    \n","    ### world_region:\n","    world_region_condition = get_libpostal_condition('world_region', '(.+?)(?=\")')\n","    results['lp_world_region'] = (\n","        results['removed_air_quotes']\n","        .map(lambda x: '' if regex.search(world_region_condition, x) is None \n","                          else regex.search(world_region_condition, x).group(1))\n","    )\n","    \n","    return results"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"55af0885-cbdd-4458-99d5-949517f7fff3","showTitle":false,"title":""}},"source":["## Parsing structured Geocode entries"]},{"cell_type":"code","execution_count":31,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"46d3e501-d8d4-40f3-bd6a-0911b98f0c05","showTitle":false,"title":""}},"outputs":[],"source":["def get_structGeo_condition(component, possible_results):\n","    '''Function that converts the component and possible_results passed to a query that filters the information from the structuredGeocode url between the quotes.\n","    \n","    :param component: TT component on which to look for the \"possible_results\" condition.\n","    :type component: str\n","    :param possible_results: Regex condition that is expected to be passed to the get_s2sG_results function in order to parse the components from the search 2 structuredGeocode endpoint. These are the possible outcomes that this value may have. For example a house number can contain spaces, letters and numbers (think of calle de Goya 23 b --> house number is: \"23 b\")\n","    :type possible_results: str\n","    '''\n","    structGeo_condition = f'\"{component}\":\"{possible_results}\"' + '[,\\}]'\n","    \n","    return structGeo_condition\n","\n","def get_s2sG_results(sdf) -> pd.DataFrame:\n","    '''Function that gets a DataFrame that contains the information on the parsed_request_quertystring column and returns a dataframe with all the parsed data.\n","    \n","    :param sdf: DataFrame that conatins all the responses from the ADX query\n","    :type sdf: pd.DataFrame\n","    :return: DataFrame with the parsed data in the structuredGeocode responses.\n","    :rtype: pd.DataFrame\n","    '''\n","    df = sdf.copy()\n","    \n","    ## Creating filter:\n","    s2sg_filter = (df['method_name'] == 'search 2 structuredGeocode')\n","    \n","    ## Removing multiple air quotes from the parsed query string:\n","    df['removed_air_quotes'] = df['parsed_request_quertystring'].map(lambda x: re.sub('\"+', '\"', re.sub(\"'+\", \"'\", x)))\n","    \n","    ## Parsing streetNumber:\n","    house_number_condition = get_structGeo_condition('streetNumber', '(.+?)(?=\")')\n","    df.loc[s2sg_filter, 'lp_house_number'] = df.loc[s2sg_filter, 'removed_air_quotes'].map(\n","        lambda x: '' if regex.search(house_number_condition, x) is None \n","        else regex.search(house_number_condition, x).group(1)\n","    )\n","    \n","    ## Parsing streetName:\n","    road_condition = get_structGeo_condition('streetName', '(.+?)(?=\")')\n","    df.loc[s2sg_filter, 'lp_road'] = df.loc[s2sg_filter, 'removed_air_quotes'].map(\n","        lambda x: '' if regex.search(road_condition, x) is None \n","        else regex.search(road_condition, x).group(1)\n","    )\n","    \n","    ## Parsing postalCode:\n","    postal_code_condition = get_structGeo_condition('postalCode', '(.+?)(?=\")')\n","    df.loc[s2sg_filter, 'lp_postal_code'] = df.loc[s2sg_filter, 'removed_air_quotes'].map(\n","        lambda x: '' if regex.search(postal_code_condition, x) is None \n","        else regex.search(postal_code_condition, x).group(1)\n","    )\n","    \n","    ## Parsing municipalitySubdivision:\n","    suburb_condition = get_structGeo_condition('municipalitySubdivision', '(.+?)(?=\")')\n","    df.loc[s2sg_filter, 'lp_suburb'] = df.loc[s2sg_filter, 'removed_air_quotes'].map(\n","        lambda x: '' if regex.search(suburb_condition, x) is None\n","        else regex.search(suburb_condition, x).group(1)\n","    )\n","    \n","    ### NOTE ON CITY DISTRICT: The only component that maps well to this is municipalitySubdivision which also maps to suburb.\n","    ### We are keeping suburb and removing city district. If we keep both daat will be repeated.\n","    ## Parsing city_district:\n","    #city_district_condition = get_structGeo_condition('municipalitySubdivision', '(.+?)(?=\")')\n","    #df['lp_city_district'] = df['removed_air_quotes'].map(lambda x: '' if regex.search(city_district_condition, x) is None \n","    #                      else regex.search(city_district_condition, x).group(1))\n","    \n","    ## Parsing municipality:\n","    city_condition = get_structGeo_condition('municipality', '(.+?)(?=\")')\n","    df.loc[s2sg_filter, 'lp_city'] = df.loc[s2sg_filter, 'removed_air_quotes'].map(\n","        lambda x: '' if regex.search(city_condition, x) is None \n","        else regex.search(city_condition, x).group(1)\n","    )\n","    \n","    ## Parsing countrySecondarySubdivision:\n","    state_district_condition = get_structGeo_condition('countrySecondarySubdivision', '(.+?)(?=\")')\n","    df.loc[s2sg_filter, 'lp_state_district'] = df.loc[s2sg_filter, 'removed_air_quotes'].map(\n","        lambda x: '' if regex.search(state_district_condition, x) is None \n","        else regex.search(state_district_condition, x).group(1)\n","    )\n","    \n","    ## Parsing countrySubdivision:\n","    state_condition = get_structGeo_condition('countrySubdivision', '(.+?)(?=\")')\n","    df.loc[s2sg_filter, 'lp_state'] = df.loc[s2sg_filter, 'removed_air_quotes'].map(\n","        lambda x: '' if regex.search(state_condition, x) is None \n","        else regex.search(state_condition, x).group(1)\n","    )\n","    \n","    ## Parsing countryCode:\n","    country_condition = get_structGeo_condition('countryCode', '(.+?)(?=\")')\n","    df.loc[s2sg_filter, 'lp_country'] = df.loc[s2sg_filter, 'removed_air_quotes'].map(\n","        lambda x: '' if regex.search(country_condition, x) is None \n","        else regex.search(country_condition, x).group(1)\n","    )\n","    \n","    return df"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"d3bb01e7-c6fc-419c-8048-bff6e4036920","showTitle":false,"title":""}},"source":["#### Generating the results columns:"]},{"cell_type":"code","execution_count":32,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"f2b2b05a-4e6e-4811-b125-37742d4fabfa","showTitle":false,"title":""}},"outputs":[],"source":["def parse_address_components(country_df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"Function that receives a DataFrame containing the sample obtained from the \"search_logs_insights\" table and returns a DataFrame with the parsed addresses for counts. The response DataFrame will contain the following boolean columns to use for counting: \n","    - has_house\n","    - has_house_num\n","    - has_road\n","    - has_unit\n","    - has_postal_code\n","    - has_locality\n","    - has_city\n","    - has_state\n","    - has_country\n","\n","    :param country_df: DataFrame containing the sample from the \"search_logs_insights\" or similar table. The table should at least contain these columns: 'house', 'house_number', 'road', 'unit', 'postcode', 'suburb', 'city_district', 'city', 'state', 'state_district' and 'country'\n","    :type country_df: pd.DataFrame\n","    :return: Returns a DataFrame with the columns stated above.\n","    :rtype: pd.DataFrame\n","    \"\"\"\n","    response = country_df.copy()\n","    \n","    empty_condition = ('', np.nan, 'False', ' ')\n","    \n","    response['has_building_name'] = response['lp_building_name'].map(lambda x: True if x not in empty_condition else False)\n","    response['has_near'] = response['lp_near'].map(lambda x: True if x not in empty_condition else False)\n","    response['has_house_num'] = response['lp_house_number'].map(lambda x: True if x not in empty_condition else False)\n","    response['has_road'] = response['lp_road'].map(lambda x: True if x not in empty_condition else False)\n","    response['has_unit'] = response['lp_unit'].map(lambda x: True if x not in empty_condition else False)\n","    response['has_floor'] = response['lp_floor'].map(lambda x: True if x not in empty_condition else False)\n","    response['has_staircase'] = response['lp_staircase'].map(lambda x: True if x not in empty_condition else False)\n","    response['has_entrance'] = response['lp_entrance'].map(lambda x: True if x not in empty_condition else False)\n","    response['has_postal_code'] = response['lp_postal_code'].map(lambda x: True if x not in empty_condition else False)\n","    response['has_po_box'] = response['lp_po_box'].map(lambda x: True if x not in empty_condition else False)\n","    response['has_suburb'] = response['lp_suburb'].map(lambda x: True if x not in empty_condition else False)\n","    response['has_city_district'] = response['lp_city_district'].map(lambda x: True if x not in empty_condition else False)\n","    response['has_city'] = response['lp_city'].map(lambda x: True if x not in empty_condition else False)\n","    response['has_island'] = response['lp_island'].map(lambda x: True if x not in empty_condition else False)\n","    response['has_state_district'] = response['lp_state_district'].map(lambda x: True if x not in empty_condition else False)\n","    response['has_state'] = response['lp_state'].map(lambda x: True if x not in empty_condition else False)\n","    response['has_country'] = response['lp_country'].map(lambda x: True if x not in empty_condition else False)\n","    response['has_country_region'] = response['lp_country_region'].map(lambda x: True if x not in empty_condition else False)\n","    response['has_world_region'] = response['lp_world_region'].map(lambda x: True if x not in empty_condition else False)\n","    \n","    return response"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"3bfbd2a5-37cf-46a0-bac6-6256352d502e","showTitle":false,"title":""}},"source":["## Complete addresses\n","\n","Include only complete addresses in the responses. This is the safest bet, as you get only what the API deems as a complete address, and so you get better responses (more complete). The problem is that you will get much less variability in your data. So if you want geometries, incomplete addresses, searches up to road level, etc., this is not your function, as it will be problematic."]},{"cell_type":"code","execution_count":33,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"309e898f-efd5-4619-a21f-fbb8a8ad844c","showTitle":false,"title":""}},"outputs":[],"source":["if only_full_addresses:\n","    responses_dict_requests = address_components_sample_generator(\n","        country_list=countries, \n","        endpoint_list=endpoint_list,\n","        table=table,\n","        sample=sample,\n","        developer_emails_list=developer_emails_list,\n","        populated_fields=None,\n","        only_full_addresses=only_full_addresses,\n","        ago=ago,\n","        check_query=False,\n","        deduplicate=deduplicate, \n","        exclude_endpoint_list=exclude_endpoint,\n","        filter_results=None\n","    )"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"453854cd-fdc6-426d-97de-414a3b35d923","showTitle":false,"title":""}},"source":["## All addresses (non-complete included)\n","\n","Use this function to if you are interested in getting the full array of responses (not only complete addresses) use this function instead. The function is the same, it simply changes a parameter so that you can get the geometries, roads, APTs, etc., within the same query."]},{"cell_type":"code","execution_count":34,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"83f60912-e0f3-4482-afe4-51e9d9368dc8","showTitle":false,"title":""}},"outputs":[],"source":["if not only_full_addresses:\n","    responses_dict_requests = address_components_sample_generator(\n","        country_list=countries, \n","        endpoint_list=endpoint_list,\n","        table=table,\n","        sample=sample,\n","        developer_emails_list=developer_emails_list,\n","        populated_fields=None,\n","        only_full_addresses=only_full_addresses,\n","        ago=ago,\n","        check_query=False,\n","        deduplicate=deduplicate,\n","        filter_results=500000\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"6679dfb0-dc4e-46ff-873f-2251575cb710","showTitle":false,"title":""}},"outputs":[],"source":["responses_dict_requests"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"d3ce88b6-4ee4-4f2a-8cb1-ca8a3037d705","showTitle":false,"title":""}},"source":["## Saving the sample"]},{"cell_type":"code","execution_count":35,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"1ceb31c0-539f-485d-81b3-438303d24744","showTitle":false,"title":""}},"outputs":[],"source":["def general_dbfs_save_function_dict_of_countries(\n","    dictionary: dict, path: str, file_type: str, name_append: str, sep: str or None = ';',\n","    selected_columns: list = ['request_uri', 'searched_query', 'populated_fields', 'countryName', 'who_searched', 'request_country', 'method_name', 'lib_postal_result', 'parsed_request_quertystring', 'developer_email', 'search_query_counts', 'country', 'components', 'number_components'], \n","    ) -> None:\n","    \"\"\"Function that saves the results of the dataframe you pass into different files following the structure: '{path}/{name_append}_{country}' and appending the format string at the end depending on which you choose.\n","    \n","    :param dictionary: Dictionary that contains the countries used to generate the samples as keys and the DataFrames of the samples as values.\n","    :type dictionary: dict\n","    :param path: String of the base path on which you want to save the content. This will be the base on which you build the saving path.\n","    :type path: str\n","    :param file_type: File type you want to save the data in. Only currently supported formats are csv and parquet.\n","    :type file_type: str\n","    :param name_append: The extension you want to paste after you base path. This will be the name of your file in the folder of the base path, without the extension!!\n","    :type name_append: str\n","    :param sep: Separator in case you use the csv format, defaults to ';'\n","    :type sep: str or None, optional\n","    :param selected_columns: The columns of the DataFrame from the sample that you want to keep. If you are in doubt keep the default options, defaults to ['request_uri', 'searched_query', 'populated_fields', 'countryName', 'who_searched', 'request_country', 'method_name', 'lib_postal_result', 'parsed_request_quertystring', 'developer_email', 'search_query_counts', 'country', 'components', 'number_components']\n","    :type selected_columns: list, optional\n","    \"\"\"\n","    for country in dictionary.keys():\n","        df = dictionary[country][selected_columns]\n","        file_path = f'{path}/{name_append}_{country}'\n","        if file_type == 'parquet':\n","            df.to_parquet(file_path + '.parquet')\n","        elif file_type == 'csv':\n","            df.to_csv((file_path + '.csv'), sep=sep, header=True)\n","        else:\n","            raise NameError(f'The file_type parameter must be \"parquet\" or \"csv\", you passed: {file_type}')\n","            \n","        print(f'{country.upper()} is done in {file_path}!!')"]},{"cell_type":"code","execution_count":36,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"032d03e7-ea92-4203-a79a-ccd06473d42c","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["PT is done in data/complete_responses_26-10-2022_PT!!\n","TR is done in data/complete_responses_26-10-2022_TR!!\n"]}],"source":["if only_full_addresses:\n","    suffix = 'in'\n","else:\n","    suffix = ''\n","\n","general_dbfs_save_function_dict_of_countries(responses_dict_requests, 'data', 'parquet', f'{suffix}complete_responses_{today}', sep=';')"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":4},"notebookName":"1.0-ADX_sample-generation","notebookOrigID":2940529096269482,"widgets":{}},"kernelspec":{"display_name":"Python 3.8.10 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"}}},"nbformat":4,"nbformat_minor":0}
